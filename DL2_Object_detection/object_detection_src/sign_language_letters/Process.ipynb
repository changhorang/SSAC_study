{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changhorang/SSAC_study/blob/main/DL2_Object_detection/object_detection_src/sign_language_letters/Process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oeon50rjoR1h"
      },
      "source": [
        "# Tensorflow Object Detection API\n",
        "- Tensorflow Object Detection API는 TensorFlow를 이용해서 Object Detection 모델을 train하고 deploy하는 것을 쉽게 도와주는 오픈소스 프레임워크.\n",
        "- https://github.com/tensorflow/models/tree/master/research/object_detection\n",
        "- Tutorial: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gScM_yqmoR1r"
      },
      "source": [
        "# Custom (Image) Data 구하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj56Eh3KoR1s"
      },
      "source": [
        "# Custom (Image) Data Labeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkMkjTMroR1s"
      },
      "source": [
        "# 전단계\n",
        "- 구글드라이브 연결\n",
        "- raw_data의 데이터압축파일을 VM local에 압축 푼다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEJ_E4APqdjy",
        "outputId": "e6fd77b6-a644-44f2-daec-6f0c98a2d841"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 압축을 풀 directory\n",
        "!mkdir images"
      ],
      "metadata": {
        "id": "dJAaITSjqfgp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "26_C0W8foR1u"
      },
      "outputs": [],
      "source": [
        "# 압축풀기 (!unzip 압축파일 -d directory)\n",
        "!unzip -q '/content/drive/MyDrive/object_detection_src/sign_language_letters/raw_data/american_sign_language_letters.zip' -d '/content/images'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhWFE3zUoR1u"
      },
      "source": [
        "# Tensorflow Object Detection 2 API 설치\n",
        "1. clone \n",
        "    - `!git clone https://github.com/tensorflow/models.git`\n",
        "1. PYTHONPATH 환경설정에 models/research 추가  \n",
        "1. 필요 모듈 설치\n",
        "    - `!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk`\n",
        "    - `!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools`\n",
        "1. proto 파일 컴파일\n",
        "    - models/research 경로로 이동\n",
        "        - `%cd models/research`\n",
        "    - `!protoc object_detection/protos/*.proto --python_out=.`\n",
        "1. setup.py 를 이용해 필요한 모듈 추가 설치\n",
        "    - setup.py를 현재 디렉토리로 카피\n",
        "        - `!cp object_detection/packages/tf2/setup.py . `\n",
        "    - 설치\n",
        "        - `!python -m pip install . `\n",
        "    - 설치 확인 - 아래 스크립트 실행시 오류 없이 실행되면 설치 잘 된 것임.\n",
        "        - `!python object_detection/builders/model_builder_tf2_test.py`\n",
        "1. 원래 디렉토리로 이동\n",
        "    - `%cd ../..`        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yIXXy_joR1w",
        "outputId": "581816ea-ada4-45d2-fc6e-d55f1d14ae71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 68137, done.\u001b[K\n",
            "remote: Total 68137 (delta 0), reused 0 (delta 0), pack-reused 68137\u001b[K\n",
            "Receiving objects: 100% (68137/68137), 576.51 MiB | 31.48 MiB/s, done.\n",
            "Resolving deltas: 100% (47885/47885), done.\n"
          ]
        }
      ],
      "source": [
        "# TF0DA2 clone\n",
        "!git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m3Hezo-QoR1x"
      },
      "outputs": [],
      "source": [
        "# models/research를 PYTHONPATH 환경설정 잡기\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "es98jn6_oR1y",
        "outputId": "abab5f7e-0f55-43c9-90b6-9691fb935cfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/env/python:/content/models/research'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "os.environ['PYTHONPATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82gNG_WpoR1y",
        "outputId": "663bc699-4fbb-469f-c4aa-639c30c43b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.4_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.6_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.6) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.6) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ],
      "source": [
        "# 필요 모듈 설치\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "K7Rp6Tk2oR1z"
      },
      "outputs": [],
      "source": [
        "!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqPhzIbXoR1z",
        "outputId": "2b5fdf82-f36a-4a02-ced0-957d097b43c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ],
      "source": [
        "# proto 파일들 컴파일\n",
        "# models/research로 이동 후 compile\n",
        "%cd models/research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5licvpczoR1z"
      },
      "outputs": [],
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup.py를 이용해서 추가 패키지 설치\n",
        "!cp object_detection/packages/tf2/setup.py . # research 밑으로 파일 복사"
      ],
      "metadata": {
        "id": "r-F739oxxnGX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BPNrUxWxm9s",
        "outputId": "378582dd-7a63-424f-84aa-42d80734afd6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.34.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 36.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.3)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 37.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.7.0)\n",
            "Collecting tensorflow-text>=2.7.0\n",
            "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 30.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.6 MB 62 kB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 55.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 51.2 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 7.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 45.1 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.42.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (12.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.22.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.5-cp37-cp37m-manylinux_2_24_x86_64.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 42.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.1)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 833 kB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: pyarrow<6.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 42.9 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 43.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: object-detection, py-cpuinfo, avro-python3, dill, future, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1683460 sha256=fa84add7dd3904224ce60cd732e46631753b3cd94f1b42405302ba39cfc5c3e5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jdb48pal/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=66c37f6406d93654113ec8c711dd3f1d96a353e70dd45b05039b5859aca29179\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=d6ab92ee51f564ec18d97f5083957ad9ffcaaa5ff7546152dd71bab12e9b2109\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=6e58a8af06206aa7098dc09b7ddc295f11747e078f3adb022698fb50026dfe73\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=63a65dc17b7dacd193c452251b9eeea2a14b2f43bb2f8e911f48f86389fc29cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=f8696e3377f2cb694a971f4ea29662f786cd08b18ea2074d692170ff2da9485c\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo avro-python3 dill future seqeval\n",
            "Installing collected packages: requests, tensorflow-io-gcs-filesystem, portalocker, future, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, orjson, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, tensorflow-io, lvis, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.22.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.22.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.22.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.34.0 avro-python3-1.9.2.1 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.7 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.4.60 orjson-3.6.5 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-6.0 requests-2.26.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.15.0 tensorflow-io-0.23.1 tensorflow-io-gcs-filesystem-0.23.1 tensorflow-model-optimization-0.7.0 tensorflow-text-2.7.3 tf-models-official-2.7.0 tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JHsIf6dyh9o",
        "outputId": "493e17b9-f592-4aa3-90fa-4fccfe09b172"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-21 07:52:04.608102: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Running tests under Python 3.7.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "W1221 07:52:05.336385 140168628393856 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.33s\n",
            "I1221 07:52:05.949388 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.33s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.31s\n",
            "I1221 07:52:07.256548 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.31s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.71s\n",
            "I1221 07:52:07.971646 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.71s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.51s\n",
            "I1221 07:52:08.478358 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.51s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.47s\n",
            "I1221 07:52:10.945047 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.47s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1221 07:52:10.946248 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I1221 07:52:10.975652 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I1221 07:52:10.994237 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I1221 07:52:11.013380 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n",
            "I1221 07:52:11.137341 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
            "I1221 07:52:11.255185 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n",
            "I1221 07:52:11.376477 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n",
            "I1221 07:52:11.500144 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n",
            "I1221 07:52:11.615271 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I1221 07:52:11.657024 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1221 07:52:11.874844 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1221 07:52:11.875052 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I1221 07:52:11.875142 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I1221 07:52:11.878051 140168628393856 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1221 07:52:11.898219 140168628393856 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1221 07:52:11.898439 140168628393856 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1221 07:52:11.964641 140168628393856 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1221 07:52:11.964853 140168628393856 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1221 07:52:12.145355 140168628393856 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1221 07:52:12.145584 140168628393856 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I1221 07:52:12.315437 140168628393856 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I1221 07:52:12.315645 140168628393856 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I1221 07:52:12.807219 140168628393856 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I1221 07:52:12.807484 140168628393856 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I1221 07:52:13.101076 140168628393856 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I1221 07:52:13.101476 140168628393856 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I1221 07:52:13.530290 140168628393856 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I1221 07:52:13.530533 140168628393856 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I1221 07:52:13.642155 140168628393856 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I1221 07:52:13.714251 140168628393856 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1221 07:52:13.778596 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1221 07:52:13.778827 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I1221 07:52:13.778892 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I1221 07:52:13.781028 140168628393856 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1221 07:52:13.805639 140168628393856 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1221 07:52:13.805834 140168628393856 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1221 07:52:13.954721 140168628393856 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1221 07:52:13.954942 140168628393856 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1221 07:52:14.224225 140168628393856 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1221 07:52:14.224454 140168628393856 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I1221 07:52:14.488771 140168628393856 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I1221 07:52:14.488986 140168628393856 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I1221 07:52:14.865709 140168628393856 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I1221 07:52:14.865917 140168628393856 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I1221 07:52:15.267324 140168628393856 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I1221 07:52:15.267591 140168628393856 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I1221 07:52:15.802881 140168628393856 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I1221 07:52:15.803085 140168628393856 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I1221 07:52:16.052945 140168628393856 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I1221 07:52:16.113195 140168628393856 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1221 07:52:16.188073 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1221 07:52:16.188276 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I1221 07:52:16.188342 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I1221 07:52:16.190495 140168628393856 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1221 07:52:16.208111 140168628393856 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1221 07:52:16.208319 140168628393856 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1221 07:52:16.351028 140168628393856 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1221 07:52:16.351249 140168628393856 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1221 07:52:16.609951 140168628393856 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1221 07:52:16.610164 140168628393856 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I1221 07:52:16.894308 140168628393856 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I1221 07:52:16.894559 140168628393856 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I1221 07:52:17.277425 140168628393856 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I1221 07:52:17.277638 140168628393856 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I1221 07:52:17.682303 140168628393856 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I1221 07:52:17.682553 140168628393856 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I1221 07:52:18.444442 140168628393856 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I1221 07:52:18.444647 140168628393856 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I1221 07:52:18.683413 140168628393856 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I1221 07:52:18.754702 140168628393856 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1221 07:52:18.837079 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1221 07:52:18.837279 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I1221 07:52:18.837342 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I1221 07:52:18.839308 140168628393856 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I1221 07:52:18.857392 140168628393856 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I1221 07:52:18.857593 140168628393856 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I1221 07:52:19.003835 140168628393856 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I1221 07:52:19.004067 140168628393856 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I1221 07:52:19.284724 140168628393856 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I1221 07:52:19.284938 140168628393856 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I1221 07:52:19.555516 140168628393856 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I1221 07:52:19.555715 140168628393856 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I1221 07:52:20.056348 140168628393856 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I1221 07:52:20.056593 140168628393856 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I1221 07:52:20.576332 140168628393856 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I1221 07:52:20.576563 140168628393856 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I1221 07:52:21.262590 140168628393856 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I1221 07:52:21.262814 140168628393856 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I1221 07:52:21.543565 140168628393856 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I1221 07:52:21.624414 140168628393856 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1221 07:52:21.711922 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1221 07:52:21.712163 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I1221 07:52:21.712234 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I1221 07:52:21.714446 140168628393856 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I1221 07:52:21.734235 140168628393856 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I1221 07:52:21.734447 140168628393856 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I1221 07:52:21.889144 140168628393856 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I1221 07:52:21.889351 140168628393856 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I1221 07:52:22.270220 140168628393856 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I1221 07:52:22.270469 140168628393856 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I1221 07:52:22.677037 140168628393856 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I1221 07:52:22.677273 140168628393856 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I1221 07:52:23.282128 140168628393856 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I1221 07:52:23.282348 140168628393856 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I1221 07:52:23.901507 140168628393856 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I1221 07:52:23.901709 140168628393856 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I1221 07:52:24.878328 140168628393856 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I1221 07:52:24.878561 140168628393856 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I1221 07:52:25.515424 140168628393856 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I1221 07:52:25.589179 140168628393856 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1221 07:52:25.682782 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1221 07:52:25.683010 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I1221 07:52:25.683100 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I1221 07:52:25.685132 140168628393856 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I1221 07:52:25.703131 140168628393856 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I1221 07:52:25.703339 140168628393856 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I1221 07:52:25.935566 140168628393856 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I1221 07:52:25.935783 140168628393856 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I1221 07:52:26.387031 140168628393856 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I1221 07:52:26.387422 140168628393856 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I1221 07:52:26.852609 140168628393856 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I1221 07:52:26.852839 140168628393856 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I1221 07:52:27.559538 140168628393856 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I1221 07:52:27.559746 140168628393856 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I1221 07:52:28.299312 140168628393856 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I1221 07:52:28.299544 140168628393856 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I1221 07:52:29.464510 140168628393856 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I1221 07:52:29.464720 140168628393856 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I1221 07:52:30.008920 140168628393856 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I1221 07:52:30.096644 140168628393856 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1221 07:52:30.203075 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1221 07:52:30.203279 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I1221 07:52:30.203343 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I1221 07:52:30.205253 140168628393856 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I1221 07:52:30.222891 140168628393856 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I1221 07:52:30.223084 140168628393856 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I1221 07:52:30.442661 140168628393856 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I1221 07:52:30.442868 140168628393856 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I1221 07:52:30.994914 140168628393856 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I1221 07:52:30.995124 140168628393856 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I1221 07:52:31.571453 140168628393856 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I1221 07:52:31.571658 140168628393856 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I1221 07:52:32.406401 140168628393856 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I1221 07:52:32.406618 140168628393856 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I1221 07:52:33.677855 140168628393856 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I1221 07:52:33.678060 140168628393856 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I1221 07:52:35.443823 140168628393856 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I1221 07:52:35.444132 140168628393856 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I1221 07:52:36.207243 140168628393856 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I1221 07:52:36.298660 140168628393856 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1221 07:52:36.437941 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1221 07:52:36.438182 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I1221 07:52:36.438278 140168628393856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I1221 07:52:36.440680 140168628393856 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I1221 07:52:36.460254 140168628393856 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I1221 07:52:36.460485 140168628393856 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I1221 07:52:36.798003 140168628393856 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I1221 07:52:36.798357 140168628393856 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I1221 07:52:37.526749 140168628393856 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I1221 07:52:37.526986 140168628393856 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I1221 07:52:38.231052 140168628393856 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I1221 07:52:38.231269 140168628393856 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I1221 07:52:39.287043 140168628393856 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I1221 07:52:39.287266 140168628393856 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I1221 07:52:40.427426 140168628393856 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I1221 07:52:40.427635 140168628393856 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I1221 07:52:42.688097 140168628393856 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I1221 07:52:42.688314 140168628393856 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I1221 07:52:43.599140 140168628393856 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I1221 07:52:43.695950 140168628393856 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 32.19s\n",
            "I1221 07:52:43.844122 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 32.19s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I1221 07:52:43.852304 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1221 07:52:43.854495 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1221 07:52:43.855152 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1221 07:52:43.856911 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1221 07:52:43.858469 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1221 07:52:43.858984 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1221 07:52:43.860103 140168628393856 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 39.246s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 이동\n",
        "%cd ../.."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u45w06iqxm0n",
        "outputId": "45e4519a-6196-444e-845d-c69db9a5b50f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksl2F4gRoR10"
      },
      "source": [
        "# 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DeRiKECQoR10"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# os.path.join('path1', 'path2', 'path3', ...) 을 이용해 하나의 path로 합쳐줌 (path1/path2/path3)\n",
        "\n",
        "BASE_PATH = '/content/drive/MyDrive/object_detection_src/sign_language_letters/workspace'\n",
        "SCRIPT_PATH = '/content/drive/MyDrive/object_detection_src/sign_language_letters/scripts' # util script 파일이 있는 경로\n",
        "TF_OD_API_PATH = '/content/models' # TF object detection api2 설치 경로\n",
        "\n",
        "IMAGE_PATH = '/content/images' # image, annotation 파일 압축 푼 경로\n",
        "LABEL_MAP_PATH = os.path.join(BASE_PATH, 'labelmap') # labelmap 설정파일 저장할 directory\n",
        "LABEL_MAP_FILE_PATH = os.path.join(LABEL_MAP_PATH, 'label_map.pbtxt') # labelmap 파일 경로\n",
        "\n",
        "# TFRecord 저장 directory - vm local\n",
        "TF_RECORD_PATH = '/content/tfrecord'\n",
        "os.makedirs(TF_RECORD_PATH, exist_ok=True) # directory생성\n",
        "\n",
        "MODEL_PATH = os.path.join(BASE_PATH, 'model') # 전이학습한 모델을 저장할 경로 (checkpoint-weights)\n",
        "CHECK_POINT_PATH = os.path.join(MODEL_PATH, 'checkpoint') # 학습한 weight 저장 경로\n",
        "EXPORT_MODEL_PATH = os.path.join(MODEL_PATH, 'export_model') # 학습한 모델 저장 경로\n",
        "PIPELINE_CONFIG_PATH = os.path.join(MODEL_PATH, 'pipeline.config') # pipeline.config 설정파일 경로\n",
        "\n",
        "# 다운받은 Pretrained 모델을 저장할 경로\n",
        "PRE_TRAINED_MODEL_PATH = os.path.join(BASE_PATH, 'pre_trained_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "puMhUm1boR11",
        "outputId": "3c8ed317-67a8-4119-886e-58a2aec39ad4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "PRE_TRAINED_MODEL_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A1X2KqnoR11"
      },
      "source": [
        "# Custom data 학습 시키기\n",
        "\n",
        "## 다음 세가지 작업이 필요\n",
        "<span style='font-weight:bold;font-size:1.3em'>1. Label Map 파일 생성</span>\n",
        "- 분류 하고자 하는 object의 class와 그 class id 를 pbtxt text 파일로 작성\n",
        "- `models\\research\\object_detection\\data`\n",
        "\n",
        "```\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'aeroplane'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 2\n",
        "  name: 'bicycle'\n",
        "}\n",
        "...\n",
        "```\n",
        "\n",
        "<span style='font-weight:bold;font-size:1.3em'>2. pipeline.config</span>\n",
        "- Model을 학습, 검증하기 위해 필요한 설정을 하는 파일\n",
        "- `models\\research\\object_detection\\samples\\configs`\n",
        "\n",
        "<span style='font-weight:bold;font-size:1.3em'>3. 학습/검증/테스트에 사용할 데이터셋을 TFRecord 로 구성</span>\n",
        "- 주요 데이터셋을 TFRecord로 생성하는 코드\n",
        "- `models\\research\\object_detection\\dataset_tools`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVgyQcdeoR12"
      },
      "source": [
        "# 설정파일 설정 및 데이터셋 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1JA8_2zoR13"
      },
      "source": [
        "# Label Map 생성\n",
        "- text (protocol buf 형식)\n",
        "- 직접 text editor를 이용해 작성\n",
        "- 코드로 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOAWJkWJoR13",
        "outputId": "9c53cb25-216b-4f6e-fcbf-3ed8bf6f5329"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "names = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
        "ids = range(1, 27)\n",
        "len(names), len(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Buub-hpxoR14"
      },
      "outputs": [],
      "source": [
        "with open(LABEL_MAP_FILE_PATH, 'wt') as fw:\n",
        "  for name, id in zip(names, ids):\n",
        "    fw.write('item {\\n')                   # item {\n",
        "    fw.write(\"\\tname:'{}'\\n\".format(name)) # TAB name='A' ENTER\n",
        "    fw.write(\"\\tid:{}\\n\".format(id))       # TAB id=1 ENTER\n",
        "    fw.write('}\\n')                        # ENTER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrw4Zfq8oR14"
      },
      "source": [
        "# TFRecord 생성\n",
        "- scripts/generate_tfrecord.py 사용\n",
        "- option (command line arguments)\n",
        "  - -x (--xml_dir): annotation 파일들이 있는 경로\n",
        "  - -l (--labels_path): LabelMap 파일\n",
        "  - -o (--output_path): tfrecord 파일\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Q1idI3NgoR14",
        "outputId": "7e0bb542-510e-4436-a30f-e4a57b8d844f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!python /content/drive/MyDrive/object_detection_src/sign_language_letters/scripts/generate_tfrecord.py -x /content/images/train -l /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/labelmap/label_map.pbtxt -o /content/tfrecord/train.tfr'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# 명령문 만들기 (train.tfr)\n",
        "f'!python {SCRIPT_PATH}/generate_tfrecord.py -x {IMAGE_PATH}/train -l {LABEL_MAP_FILE_PATH} -o {TF_RECORD_PATH}/train.tfr'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biwuNXmqoR14",
        "outputId": "2dfeec46-23c4-4268-d800-3376724795c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-21 07:52:50.075036: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Successfully created the TFRecord file: /content/tfrecord/train.tfr\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/object_detection_src/sign_language_letters/scripts/generate_tfrecord.py -x /content/images/train -l /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/labelmap/label_map.pbtxt -o /content/tfrecord/train.tfr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7GSrMHRWoR15",
        "outputId": "a760f49b-704e-4c3d-a7b0-745462d54512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!python /content/drive/MyDrive/object_detection_src/sign_language_letters/scripts/generate_tfrecord.py -x /content/images/test -l /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/labelmap/label_map.pbtxt -o /content/tfrecord/test.tfr'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# 명령문 만들기 (test.tfr)\n",
        "f'!python {SCRIPT_PATH}/generate_tfrecord.py -x {IMAGE_PATH}/test -l {LABEL_MAP_FILE_PATH} -o {TF_RECORD_PATH}/test.tfr'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/object_detection_src/sign_language_letters/scripts/generate_tfrecord.py -x /content/images/test -l /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/labelmap/label_map.pbtxt -o /content/tfrecord/test.tfr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zavJYb_WgMf-",
        "outputId": "5c6b6214-3308-485d-bcca-838f54b25094"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-21 07:52:57.354445: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Successfully created the TFRecord file: /content/tfrecord/test.tfr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "C0U_u0BPoR15",
        "outputId": "77c784f8-25ec-4989-cfc0-cf417f2566b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!python /content/drive/MyDrive/object_detection_src/sign_language_letters/scripts/generate_tfrecord.py -x /content/images/valid -l /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/labelmap/label_map.pbtxt -o /content/tfrecord/valid.tfr'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# 명령문 만들기 (valid.tfr)\n",
        "f'!python {SCRIPT_PATH}/generate_tfrecord.py -x {IMAGE_PATH}/valid -l {LABEL_MAP_FILE_PATH} -o {TF_RECORD_PATH}/valid.tfr'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/object_detection_src/sign_language_letters/scripts/generate_tfrecord.py -x /content/images/valid -l /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/labelmap/label_map.pbtxt -o /content/tfrecord/valid.tfr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0NmgbuLgO4N",
        "outputId": "78ad3285-10cd-455b-945d-9bbca90dcb40"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-21 07:53:01.642300: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Successfully created the TFRecord file: /content/tfrecord/valid.tfr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tfrecord 파일들을 google drive에 backup (복사)\n",
        "!cp /content/tfrecord/*.tfr /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/tfrecord"
      ],
      "metadata": {
        "id": "TS5CaF2qfhi8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tfrecord 파일들을 google drive에 backup (복사)\n",
        "!cp /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/tfrecord/*.tfr /content/tfrecord"
      ],
      "metadata": {
        "id": "FyGwHUsggE01"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC34ZKQCoR15"
      },
      "source": [
        "# Pretrained Model Download\n",
        "- Tensorflow object detection API는 MS COCO 2017 dataset으로 미리 학습시킨 다양한 Object Detection 모델을 제공한다.\n",
        "- tf2 detection Model Zoo: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
        "- SSD MobileNet V2 FPNLite 320x320 다운로드\n",
        "    - 성능은 떨어지지만 학습속도가 빠르다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZhdee51oR15",
        "outputId": "ef134e8b-d956-4cbe-85e2-3839c4e23eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-21 07:53:03--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.212.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.212.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-12-21 07:53:03 (138 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# wget url : url의 파일을 다운로드\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QSyrOVgooR15",
        "outputId": "37bbf92f-eae2-4d46-d952-9421fd997d50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!mv ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# workspace/pre_trained_model로 옮긴 뒤 압축풀기\n",
        "# mv 옮길 파일 directory\n",
        "f'!mv ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz {PRE_TRAINED_MODEL_PATH}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IE0ioCwwoR16"
      },
      "outputs": [],
      "source": [
        "!mv ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HZiI9FkjoR16",
        "outputId": "52e99dc3-0b61-4da4-ab03-7c2e542aa0b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!tar -zxvf  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz  -C  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model'"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# tar -zxvf 압축파일 -C directory\n",
        "f'!tar -zxvf  {PRE_TRAINED_MODEL_PATH}/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz  -C  {PRE_TRAINED_MODEL_PATH}'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -zxvf  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz  -C  /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEvFcTv6i93O",
        "outputId": "399ac418-c079-4d44-9724-d2a75cd3dafc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9rgo9_poR16"
      },
      "source": [
        "# Pipeline.config 설정 변경"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buzTRD3ioR16"
      },
      "source": [
        "## pipeline.config  파일 개요\n",
        "- Model을 학습, 검증하기 위해 필요한 설정을 하는 파일\n",
        "- 구조\n",
        "    - https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md\n",
        "    - **model**\n",
        "        - 사용하는 모델에 대한 설정\n",
        "        - class 개수\n",
        "        - 입력이미지 size\n",
        "        - anchor 설정\n",
        "    - **train_config**\n",
        "        - Train(학습)관련 설정\n",
        "        - batch_size\n",
        "            - 사용하는 GPU의 메모리 크기에 맞게 조절한다.\n",
        "        - image augmentation관련 설정 등\n",
        "        - optimizer관련 설정\n",
        "        - 학습에 사용할 weight 파일의 경로\n",
        "    - **train_input_reader**\n",
        "        - labelmap 파일 경로\n",
        "        - train tfrecord 파일 경로\n",
        "    - **eval_config**\n",
        "        - evaluation(평가)을 위해 사용하는 metric 설정\n",
        "    - **eval_input_reader**\n",
        "        - labelmap 파일 경로\n",
        "        - evaluation tfreord 파일 경로\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9D5Rp0YoR16"
      },
      "source": [
        "## Pretrain model의 pipeline.config 파일 카피\n",
        "- pretrained 모델의 압축을 풀면 pipeline.config 파일이 있다.\n",
        "- workspace\\model 로 copy 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QOzPgVxBoR17",
        "outputId": "1db852f3-e715-4182-c1c3-d04c300c2fa9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!cp /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/model/pipeline.config'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "f\"!cp {os.path.join(PRE_TRAINED_MODEL_PATH, 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8', 'pipeline.config')} {PIPELINE_CONFIG_PATH}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "t1Ub-m4ooR17"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/pre_trained_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config /content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/model/pipeline.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VTk6_XAoR17"
      },
      "source": [
        "## pipeline.config 설정 변경\n",
        "- pipeline.config 내용 변경은 파일을 **직접 변경**할 수도 있고 **코드상에서 변경**할 수도 있다.\n",
        "\n",
        "### 필수 변경사항\n",
        "-  class개수 변경 (config file 수정)\n",
        "-  train 배치 사이즈 변경 - gpu 메모리 사양에 맞게 변경한다.\n",
        "-  pretrained model CHECKPOINT가 저장된 경로 설정\n",
        "-  pretrained model이 어떤 종류의 모델인지 설정\n",
        "-  train 관련 변경\n",
        "    -  labelmap 파일 경로 설정\n",
        "    -  train 용 tfrecord 파일 경로 지정\n",
        "-  evaluation 관련 변경\n",
        "    -  labelmap 파일 경로 설정\n",
        "    -  evaluation 용 tfrecord 파일 경로 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lVmYFiUYoR18"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVLO53e6oR18",
        "outputId": "a4097db0-29b9-4a98-b43d-f0ebebb92b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# pipeline.config 파일을 읽어서 확인 (수정과 상관없이 내용확인)\n",
        "config = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH) # 설정을 읽어서 dict로 반환\n",
        "print(type(config))\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr2Y7yiGoR18",
        "outputId": "cb958346-55cf-41c0-ecd7-df950d937fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'object_detection.protos.pipeline_pb2.TrainEvalPipelineConfig'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# 빈 pipeline.config를 생성\n",
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "print(type(pipeline_config))\n",
        "pipeline_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Vv6-wv5aoR18"
      },
      "outputs": [],
      "source": [
        "# pipeline.config를 text로 읽어서 빈 pipeline.config에 넣음\n",
        "with tf.io.gfile.GFile(PIPELINE_CONFIG_PATH, 'r') as fr: # tf.io.gfile.GFile() == open()\n",
        "  proto_str = fr.read()\n",
        "  text_format.Merge(proto_str, pipeline_config) # 읽은 pipeline 텍스트를 TrainEvalPipelineConfig 객체에 덮어씌우기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKhnGVOdoR18",
        "outputId": "49c6ec81-fc55-4990-b521-04844fb1d0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model {\n",
            "  ssd {\n",
            "    num_classes: 90\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 320\n",
            "        width: 320\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
            "      depth_multiplier: 1.0\n",
            "      min_depth: 16\n",
            "      conv_hyperparams {\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 3.9999998989515007e-05\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          random_normal_initializer {\n",
            "            mean: 0.0\n",
            "            stddev: 0.009999999776482582\n",
            "          }\n",
            "        }\n",
            "        activation: RELU_6\n",
            "        batch_norm {\n",
            "          decay: 0.996999979019165\n",
            "          scale: true\n",
            "          epsilon: 0.0010000000474974513\n",
            "        }\n",
            "      }\n",
            "      use_depthwise: true\n",
            "      override_base_feature_extractor_hyperparams: true\n",
            "      fpn {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        additional_layer_depth: 128\n",
            "      }\n",
            "    }\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      weight_shared_convolutional_box_predictor {\n",
            "        conv_hyperparams {\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 3.9999998989515007e-05\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              mean: 0.0\n",
            "              stddev: 0.009999999776482582\n",
            "            }\n",
            "          }\n",
            "          activation: RELU_6\n",
            "          batch_norm {\n",
            "            decay: 0.996999979019165\n",
            "            scale: true\n",
            "            epsilon: 0.0010000000474974513\n",
            "          }\n",
            "        }\n",
            "        depth: 128\n",
            "        num_layers_before_predictor: 4\n",
            "        kernel_size: 3\n",
            "        class_prediction_bias_init: -4.599999904632568\n",
            "        share_prediction_tower: true\n",
            "        use_depthwise: true\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      multiscale_anchor_generator {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        anchor_scale: 4.0\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        scales_per_octave: 2\n",
            "      }\n",
            "    }\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 9.99999993922529e-09\n",
            "        iou_threshold: 0.6000000238418579\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "        use_static_shapes: false\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    loss {\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          gamma: 2.0\n",
            "          alpha: 0.25\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "  }\n",
            "}\n",
            "train_config {\n",
            "  batch_size: 128\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_crop_image {\n",
            "      min_object_covered: 0.0\n",
            "      min_aspect_ratio: 0.75\n",
            "      max_aspect_ratio: 3.0\n",
            "      min_area: 0.75\n",
            "      max_area: 1.0\n",
            "      overlap_thresh: 0.0\n",
            "    }\n",
            "  }\n",
            "  sync_replicas: true\n",
            "  optimizer {\n",
            "    momentum_optimizer {\n",
            "      learning_rate {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: 0.07999999821186066\n",
            "          total_steps: 50000\n",
            "          warmup_learning_rate: 0.026666000485420227\n",
            "          warmup_steps: 1000\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.8999999761581421\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
            "  num_steps: 50000\n",
            "  startup_delay_steps: 0.0\n",
            "  replicas_to_aggregate: 8\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "  fine_tune_checkpoint_type: \"classification\"\n",
            "  fine_tune_checkpoint_version: V2\n",
            "}\n",
            "train_input_reader {\n",
            "  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
            "  }\n",
            "}\n",
            "eval_config {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "}\n",
            "eval_input_reader {\n",
            "  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(pipeline_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "KqBkZ6QVoR18"
      },
      "outputs": [],
      "source": [
        "# 수정\n",
        "# 설정 계층 구조에 맞게 '.' 표기법을 이용해 접근\n",
        "\n",
        "# 검출해야하는 object 개수를 변경 (class)\n",
        "pipeline_config.model.ssd.num_classes = 26\n",
        "\n",
        "# 배치 size 변경 - gpu메모리에 맞춰 최대한 크게 잡기\n",
        "pipeline_config.train_config.batch_size = 8\n",
        "\n",
        "# Pretrained 모델의 checkpoint 파일(weight) 경로 지정\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(PRE_TRAINED_MODEL_PATH, 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8', 'checkpoint', 'ckpt-0')\n",
        "\n",
        "# Pretrained 모델이 어떤 종류를 학습한 모델인지 설정\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = 'detection' # object detection\n",
        "\n",
        "\n",
        "# train_input_reader 설정\n",
        "# LabelMap 파일 경로 설정\n",
        "pipeline_config.train_input_reader.label_map_path = LABEL_MAP_FILE_PATH\n",
        "\n",
        "# train.tfr 경로 설정\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(TF_RECORD_PATH, 'train.tfr')]\n",
        "\n",
        "# eval_input_reader 설정\n",
        "# LabelMap 파일 경로 설정\n",
        "pipeline_config.eval_input_reader[0].label_map_path = LABEL_MAP_FILE_PATH\n",
        "\n",
        "# eval.tfr 경로 설정\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(TF_RECORD_PATH, 'test.tfr')]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TrainEvalPipelineConfig의 변경된 설정을 파일에 쓰기\n",
        "# TrainEvalPipelineConfig객체의 내용을 string으로 변환\n",
        "config_txt = text_format.MessageToString(pipeline_config)\n",
        "print(type(config_txt))\n",
        "\n",
        "with tf.io.gfile.GFile(PIPELINE_CONFIG_PATH, 'wb') as fw: # gfile의 경우, wt가 아닌 wb\n",
        "  fw.write(config_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BjQXrKx23We",
        "outputId": "5458d459-36dc-45c4-b60f-1446077f72bd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGrMIfMpoR18"
      },
      "source": [
        "# Model 학습\n",
        "- 다음 명령어를 실행한다.\n",
        "- 시간이 오래 걸리므로 terminal에서 실행한다.\n",
        "```\n",
        "python models/research/object_detection/model_main_tf2.py --model_dir=workspace/model/checkpoint --pipeline_config_path=workspace/model/pipeline.config --num_train_steps=3000\n",
        "```\n",
        "\n",
        "## 옵션\n",
        "- model_dir: 학습한 모델의 checkpoint 파일을 저장할 경로. (1000 step당 저장한다.)\n",
        "- pipeline_config_path: pipeline.config 파일 경로\n",
        "- num_train_steps: 학습할 step 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "scZoAwU3oR19",
        "outputId": "0ed264d3-855c-4ab0-c419-7d97414a0ff5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!python /content/models/research/object_detection/model_main_tf2.py --model_dir=/content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/model/checkpoint --pipeline_config_path=/content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/model/pipeline.config --num_train_steps=20000'"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "f'!python {os.path.join(TF_OD_API_PATH, \"research\", \"object_detection\", \"model_main_tf2.py\")} \\\n",
        "--model_dir={CHECK_POINT_PATH} \\\n",
        "--pipeline_config_path={PIPELINE_CONFIG_PATH} \\\n",
        "--num_train_steps=20000'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rFLm1K7oR19",
        "outputId": "443af206-d04d-413c-f002-f1a9837abb79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-21 07:53:12.940884: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "W1221 07:53:12.942646 140615455025024 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I1221 07:53:12.943714 140615455025024 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 20000\n",
            "I1221 07:53:12.950334 140615455025024 config_util.py:552] Maybe overwriting train_steps: 20000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1221 07:53:12.950599 140615455025024 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1221 07:53:12.988701 140615455025024 deprecation.py:347] From /content/models/research/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tfrecord/train.tfr']\n",
            "I1221 07:53:13.030228 140615455025024 dataset_builder.py:163] Reading unweighted datasets: ['/content/tfrecord/train.tfr']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tfrecord/train.tfr']\n",
            "I1221 07:53:13.030555 140615455025024 dataset_builder.py:80] Reading record datasets for input file: ['/content/tfrecord/train.tfr']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1221 07:53:13.030672 140615455025024 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1221 07:53:13.030764 140615455025024 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1221 07:53:13.038779 140615455025024 deprecation.py:347] From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1221 07:53:13.082715 140615455025024 deprecation.py:347] From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1221 07:53:21.691351 140615455025024 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1221 07:53:25.574982 140615455025024 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1221 07:53:27.482905 140615455025024 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-12-21 07:53:30.715114: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "2021-12-21 07:53:30.921561: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at multi_device_iterator_ops.cc:789 : NOT_FOUND: Resource AnonymousMultiDeviceIterator/AnonymousMultiDeviceIterator0/N10tensorflow4data12_GLOBAL__N_119MultiDeviceIteratorE does not exist.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W1221 07:53:57.226444 140612605007616 deprecation.py:551] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 4.129s\n",
            "I1221 08:00:49.637318 140615455025024 model_lib_v2.py:707] Step 100 per-step time 4.129s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.86393,\n",
            " 'Loss/localization_loss': 0.3735468,\n",
            " 'Loss/regularization_loss': 0.15353368,\n",
            " 'Loss/total_loss': 1.3910105,\n",
            " 'learning_rate': 0.0319994}\n",
            "I1221 08:00:49.637970 140615455025024 model_lib_v2.py:708] {'Loss/classification_loss': 0.86393,\n",
            " 'Loss/localization_loss': 0.3735468,\n",
            " 'Loss/regularization_loss': 0.15353368,\n",
            " 'Loss/total_loss': 1.3910105,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 3.713s\n",
            "I1221 08:07:00.958092 140615455025024 model_lib_v2.py:707] Step 200 per-step time 3.713s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.5558982,\n",
            " 'Loss/localization_loss': 0.0996975,\n",
            " 'Loss/regularization_loss': 0.15356037,\n",
            " 'Loss/total_loss': 0.80915606,\n",
            " 'learning_rate': 0.0373328}\n",
            "I1221 08:07:00.959060 140615455025024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5558982,\n",
            " 'Loss/localization_loss': 0.0996975,\n",
            " 'Loss/regularization_loss': 0.15356037,\n",
            " 'Loss/total_loss': 0.80915606,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 3.787s\n",
            "I1221 08:13:19.644358 140615455025024 model_lib_v2.py:707] Step 300 per-step time 3.787s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.47336164,\n",
            " 'Loss/localization_loss': 0.06522458,\n",
            " 'Loss/regularization_loss': 0.15345362,\n",
            " 'Loss/total_loss': 0.69203985,\n",
            " 'learning_rate': 0.0426662}\n",
            "I1221 08:13:19.644787 140615455025024 model_lib_v2.py:708] {'Loss/classification_loss': 0.47336164,\n",
            " 'Loss/localization_loss': 0.06522458,\n",
            " 'Loss/regularization_loss': 0.15345362,\n",
            " 'Loss/total_loss': 0.69203985,\n",
            " 'learning_rate': 0.0426662}\n"
          ]
        }
      ],
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py --model_dir=/content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/model/checkpoint --pipeline_config_path=/content/drive/MyDrive/object_detection_src/sign_language_letters/workspace/model/pipeline.config --num_train_steps=20000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C3nAYx9oR19"
      },
      "source": [
        "# 학습한 모델 추출(export)\n",
        "- `models/research/object_detection/exporter_main_v2.py` 사용\n",
        "- 옵션\n",
        "    - `exporter_main_v2.py --helpshort || exporter_main_v2.py --helpfull`\n",
        "    - input_type : input node type\n",
        "        - image_tensor, encoded_image_string_tensor\n",
        "    - train_checkpoint: 학습된 checkpoint 파일이 저장된 경로(folder/directory)\n",
        "    - pipeline_config_path: pipeline.config 파일의 경로 (파일명 포함)\n",
        "    - output_directory: export된 모델을 저장할 경로.\n",
        "- 추출된 디렉토리 구조\n",
        "```bash\n",
        "output_dir\n",
        "├─ checkpoint/\n",
        "├─ saved_model/\n",
        "└─ pipeline.config\n",
        "```\n",
        "    - checkpoint: custom data 학습한 checkpoint 파일들을 이 디렉토리로 복사한다.\n",
        "    - save_model: pipeline.config 설정에 맞춰 생성된 model\n",
        "    - pipeline.config: pipeline.config 설정파일"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp5HYzyXoR19"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9H9d4NyaoR19"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sUz-eA7oR1-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hva4ebZtoR1-"
      },
      "source": [
        "# Inference(추론)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JccZN_yoR1-"
      },
      "source": [
        "### 사용 함수,메소드\n",
        "-  ### tf.convert_to_tensor(array_like, dtype)\n",
        "    - array_like 를 Tensoflow Tensor 객체로 변환\n",
        "    - `tf.convert_to_tensor([[1,2],[3,4]])`\n",
        "- ### detection_model.preprocess(image 4차원 ndarray)\n",
        "    - 전달받은 이미지를 model의 input shape에 맞게 resizing 한다.\n",
        "    - 반환값: (resize된 image Tensor, 이미지의 shape) 을 tuple로 반환\n",
        "- ### detection_model.predict(image tensor, image_shape tensor)\n",
        "    - 추론/detection 메소드\n",
        "    - 이미지와 image shape을 받아서 detection한 결과를 딕셔너리로 반환한다.\n",
        "    - **반환 dictionary key**\n",
        "        - **preprocessed_inputs**:  입력 이미지 Tensor. preprocess()로 처리된 이미지. \n",
        "        - **feature_maps**: List. feature map 들을 반환\n",
        "        - **anchors**: 2D Tensor. normalize 된 anchor box들의 좌표를 반환. 2-D float tensor: \\[num_anchors, 4\\]\n",
        "        - **final_anchors**: 3D Tensor. batch 당 anchors. (anchors에 batch가 포함된 것). \\[batch_size, num_anchors, 4\\]\n",
        "        - **box_encodings**: 3D float tensor. predict한 box들의 normalize된 좌표. \\[batch_size, num_anchors,box_code_dimension\\]\n",
        "        - **class_predictions_with_background**: 3D Tensor. 클래스 확률을 반환.(logit). \\[batch_size, num_anchors, num_classes+1]\\\n",
        "            - background 확률을 포함해서 num_classes+1개가 된다. (index 0: background)\n",
        "            \n",
        "- ### detection_model.postprocess(prediction_dict, shape)\n",
        "    - predict()가 예측한 결과에서 **Non-Maxinum Suppression**을 실행해서 최종 Detection 결과를 반환한다.\n",
        "        - predict()는 anchor별로 예측결과를 모아서 주고 post-process는 최종 결과를 추출해서 반환.\n",
        "    - **반환 dictionary key**\n",
        "        - **num_detections**: Detect한 개수 (bounding box 개수)\n",
        "        - **detection_boxes**: [batch, max_detections, 4]. 후처리한 detection box\n",
        "        - **detection_scores**: [batch, max_detections]. post-processed detection box들의 detection score들 (detection score는 box안에 물체가 있을 확률값 - confidence score).\n",
        "        - **detection_classes**: [batch, max_detections] tensor with classes for post-processed detection classes.\n",
        "        - **raw_detection_boxes**:[batch, total_detections, 4] Non-Max Suppression 하기 전의 감지된 box들\n",
        "        - **raw_detection_scores**: [batch, total_detections, num_classes_with_background]. raw detection box들의 class별 점수\n",
        "        - **detection_multiclass_scores**: [batch, max_detections, num_classes_with_background] post-processed이후 남은 bounding box 들의 class별 점수. LabelMap의 class에 background가 추가되어 계산된다.\n",
        "        - **detection_anchor_indices**: [batch, max_detections] post-processed 이후 나은 anchor box의 index들."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa16hPcnoR1-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkonRoC4oR1-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miXQl80boR1_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAHgRVtQoR1_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDUDN-o3oR1_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbjSXsxSoR1_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4JMmN46oR1_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkV6CEBFoR2A"
      },
      "source": [
        "# 새로운 이미지 Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH_pHgdvoR2A"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LXwkW2WoR2A"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_Zd1CEooR2A"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gK4VCRCyoR2A"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Process.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Oeon50rjoR1h",
        "gScM_yqmoR1r",
        "xj56Eh3KoR1s",
        "GkMkjTMroR1s",
        "AhWFE3zUoR1u",
        "Ksl2F4gRoR10",
        "8A1X2KqnoR11",
        "IVgyQcdeoR12",
        "p1JA8_2zoR13",
        "buzTRD3ioR16",
        "5JccZN_yoR1-"
      ],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}